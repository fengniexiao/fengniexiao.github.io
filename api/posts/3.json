{"title":"爬虫被识别处理方法","slug":"爬虫被识别处理方法","date":"2020-06-10","updated":"2020-06-10","comments":true,"path":"api/posts/3.json","excerpt":"<ul><li> 在爬取某个网站大量数据时，免不了多次请求，机械的请求很容易被识别，导致爬取中断。</li><li> 在爬虫中设置，达到模拟人为的请求。</li><li> 改变请求头和 ip、cookie 等防止被识别。</li></ul>","cover":"http://ww1.sinaimg.cn/large/e92dbddbgy1ggiqjon642j20hn0dhq5f.jpg","covers":["http://ww1.sinaimg.cn/large/e92dbddbgy1ggiqjon642j20hn0dhq5f.jpg"],"content":"<ul><li>在爬取某个网站大量数据时，免不了多次请求，机械的请求很容易被识别，导致爬取中断。</li><li>在爬虫中设置，达到模拟人为的请求。</li><li>改变请求头和 ip、cookie 等防止被识别。</li></ul><a id=\"more\"></a><h1>伪造 User-Agent</h1><p><strong>在请求头中把 User-Agent 设置成浏览器中的 User-Agent，来伪造浏览器访问 </strong></p><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">headers &#x3D; &#123;&#39;User-Agent&#39;:&#39;Mozilla&#x2F;5.0 (X11; Linux x86_64) AppleWebKit&#x2F;537.36 (KHTML, like Gecko) Chrome&#x2F;52.0.2743.116 Safari&#x2F;537.36&#39;&#125;</span><br></pre></td></tr></table></figure><p><strong> 现在可以直接使用相关的库，每调用一次库会自动生成一个请求头 </strong><br> 例如：fake-useragent</p><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">from fake_useragent import UserAgent</span><br><span class=\"line\">ua &#x3D; UserAgent()</span><br><span class=\"line\"></span><br><span class=\"line\">#ie 浏览器的 user agent</span><br><span class=\"line\">print(ua.ie)</span><br><span class=\"line\">#opera 浏览器 </span><br><span class=\"line\">print(ua.opera)</span><br><span class=\"line\">#chrome 浏览器</span><br><span class=\"line\">print(ua.chrome)</span><br><span class=\"line\">#firefox 浏览器</span><br><span class=\"line\">print(ua.firefox)</span><br><span class=\"line\">#safri 浏览器</span><br><span class=\"line\">print(ua.safari)</span><br><span class=\"line\"># 最常用的方式</span><br><span class=\"line\"># 写爬虫最实用的是可以随意变换 headers，一定要有随机性。支持随机生成请求头</span><br><span class=\"line\">print(ua.random)</span><br></pre></td></tr></table></figure><h1> 在每次重复爬取之间设置一个随机时间间隔 </h1><p><strong> 代码自动请求网址速度过快，很容易被识别出爬虫，设置随机的时间间隔，可达到跟好的模拟效果 </strong></p><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">time.sleep(random.random(3,4.5,5,3.5,4))</span><br></pre></td></tr></table></figure><h1> 伪造 cookies</h1><p>可以将浏览器中的 cookies 复制过来使用 <br><img src=\"http://ww1.sinaimg.cn/large/e92dbddbgy1ggiqjon642j20hn0dhq5f.jpg\" alt=\"PVC)@5FM}KR.png\"></p><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># 也可以仿造其网站的 cookies</span><br><span class=\"line\">import requests</span><br><span class=\"line\"></span><br><span class=\"line\">jar &#x3D; requests.cookies.RequestsCookieJar()</span><br><span class=\"line\">jar.set(&#39;bid&#39;, &#39;ehjk9OLdwha&#39;, domain&#x3D;&#39;.douban.com&#39;, path&#x3D;&#39;&#x2F;&#39;)</span><br><span class=\"line\">jar.set(&#39;11&#39;, &#39;25678&#39;, domain&#x3D;&#39;.douban.com&#39;, path&#x3D;&#39;&#x2F;&#39;)</span><br><span class=\"line\">url &#x3D; &#39;https:&#x2F;&#x2F;book.douban.com&#x2F;people&#x2F;122624856&#x2F;collect&#39;</span><br><span class=\"line\">r &#x3D; requests.get(url, cookies&#x3D;jar)</span><br><span class=\"line\">print(r.text)</span><br></pre></td></tr></table></figure><p><strong> 若想了解跟多 cookies 的信息可访问 (<a href=\"https://www.cnblogs.com/Summer-skr--blog/p/11403944.html\" target=\"_blank\" rel=\"noopener external nofollow noreferrer\">https://www.cnblogs.com/Summer-skr--blog/p/11403944.html</a>)</strong></p><h1> 换着用多个代理 IP 来进行访问，防止同一个 IP 发起过多请求而被封 IP</h1><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">proxies &#x3D; &#123;&#39;http&#39;:&#39;http:&#x2F;&#x2F;10.10.10.10:8765&#39;,&#39;https&#39;:&#39;https:&#x2F;&#x2F;10.10.10.10:8765&#39;&#125;</span><br><span class=\"line\">resp &#x3D; requests.get(url,proxies &#x3D; proxies)</span><br></pre></td></tr></table></figure><p><strong>可以爬取免费代理，验证可用 ip 组成 ip 列表，循环一定时间后随机选择一个 ip 使用 </strong></p><h1> 识别网站的验证码，以解封 ip</h1><p><strong>可以将验证码解算器集成到爬虫系统中。例如，验证码识别服务供应商 Death by CAPTCHA 和 Bypass CAPTCHA 都允许用户通过调用 API 服务来进行自动打码，从而在抓取数据过程中自动解决验证码。这些验证码解决工具可以处理普通的文本验证码，甚至是更高级的验证码。</strong></p><h1>ADSL+ 脚本监测 ip 是否被封 </h1><p><strong> 通过脚本来检测 IP 是否被封，封了就通过 ADSL 来切换 ip</strong></p><h1>其他 </h1><p><strong> 还有些其他方法以避免被网站识别，如：多申请线路分布不同区域，不同的 ip 分配任务多爬等</strong></p>","url":"/posts/3/","min2read":3,"word4post":721,"prev_post":{"title":"python 爬虫同步 (一般)、并发 (多线程)、异步、框架 scrapy 使用","url":"/posts/4/"},"next_post":{"title":"使用 Mustom 主题经过和报错","url":"/posts/1/"},"toc":"<ol class=\"toc\"><li class=\"toc-item toc-level-1\"><a class=\"toc-link\" data-id=\"\" href = \"#\"><span class=\"toc-number\">1.</span> <span class=\"toc-text\">伪造 User-Agent</span></a></li><li class=\"toc-item toc-level-1\"><a class=\"toc-link\" data-id=\"\" href = \"#\"><span class=\"toc-number\">2.</span> <span class=\"toc-text\"> 在每次重复爬取之间设置一个随机时间间隔 </span></a></li><li class=\"toc-item toc-level-1\"><a class=\"toc-link\" data-id=\"\" href = \"#\"><span class=\"toc-number\">3.</span> <span class=\"toc-text\"> 伪造 cookies</span></a></li><li class=\"toc-item toc-level-1\"><a class=\"toc-link\" data-id=\"\" href = \"#\"><span class=\"toc-number\">4.</span> <span class=\"toc-text\"> 换着用多个代理 IP 来进行访问，防止同一个 IP 发起过多请求而被封 IP</span></a></li><li class=\"toc-item toc-level-1\"><a class=\"toc-link\" data-id=\"\" href = \"#\"><span class=\"toc-number\">5.</span> <span class=\"toc-text\"> 识别网站的验证码，以解封 ip</span></a></li><li class=\"toc-item toc-level-1\"><a class=\"toc-link\" data-id=\"\" href = \"#\"><span class=\"toc-number\">6.</span> <span class=\"toc-text\">ADSL+ 脚本监测 ip 是否被封 </span></a></li><li class=\"toc-item toc-level-1\"><a class=\"toc-link\" data-id=\"\" href = \"#\"><span class=\"toc-number\">7.</span> <span class=\"toc-text\">其他 </span></a></li></ol>","categories":[{"name":"python","path":"api/categories/python.json","url":"/categories/python/"}],"tags":[{"name":"爬虫","path":"api/tags/爬虫.json","url":"/tags/爬虫/"}]}