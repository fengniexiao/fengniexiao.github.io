{"title":"python 爬虫同步 (一般)、并发 (多线程)、异步、框架 scrapy 使用","slug":"python爬虫同、并发、异步、框架使用","date":"2020-06-25","updated":"2020-06-26","comments":true,"path":"api/posts/4.json","excerpt":"<ul><li>同步、并发、异步、框架 </li><li> 同步使用 </li><li> 并发使用 </li><li> 异步使用 </li><li> 框架使用</li></ul>","cover":null,"covers":null,"content":"<ul><li>同步、并发、异步、框架 </li><li> 同步使用 </li><li> 并发使用 </li><li> 异步使用 </li><li> 框架使用 </li></ul><a id=\"more\"></a><h1> 同步、并发、异步、框架概念区别 </h1><p><strong> 同步 </strong>: 进程之间存在依赖关系，一个进程结束的输出作为另一个进程的输入。<br><strong> 并发 </strong>: 通过多个执行器同时执行一个大任务来缩短执行时间、提高执行效率的方法。<br><strong> 多线程 </strong>: 多线程是并发的一种重要形式，能够实现线程之间的切换执行.。<br><strong> 异步 </strong>: 和同步相对，同步是顺序执行，而异步是彼此独立，在等待某个事件的过程中继续做自己的事，不要等待这一事件完成后再工作。线程是实现异步的一个方式，异步是让调用方法的主线程不需要同步等待另一个线程的完成，从而让主线程干其他事情。<br><strong>scrapy</strong>: 主要集合了 Twisted['twɪstɪd] 异步网络框架等</p><h1> 一般方法（同步、requests+beautifulsoup）</h1><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">import requests</span><br><span class=\"line\">from bs4 import BeautifulSoup</span><br><span class=\"line\">import time</span><br><span class=\"line\">import math</span><br><span class=\"line\"></span><br><span class=\"line\"># 开始时间 </span><br><span class=\"line\">t1 &#x3D; time.time()</span><br><span class=\"line\"></span><br><span class=\"line\">url &#x3D; &quot;https:&#x2F;&#x2F;cd.lianjia.com&#x2F;ershoufang&#x2F;&quot;</span><br><span class=\"line\"># 请求头部</span><br><span class=\"line\">headers &#x3D; &#123;&#39;User-Agent&#39;: &#39;Mozilla&#x2F;5.0 (Windows NT 10.0; WOW64) AppleWebKit&#x2F;537.36 (KHTML, like Gecko) Chrome&#x2F;67.0.3396.87 Safari&#x2F;537.36&#39;&#125;</span><br><span class=\"line\"># 发送 HTTP 请求</span><br><span class=\"line\">req &#x3D; requests.get(url, headers&#x3D;headers)</span><br><span class=\"line\"># 解析网页</span><br><span class=\"line\">soup &#x3D; BeautifulSoup(req.text, &quot;lxml&quot;)</span><br><span class=\"line\"># 找到爬取页数</span><br><span class=\"line\">info_num &#x3D; int(soup.xpath(&quot;&#x2F;html&#x2F;body&#x2F;div[4]&#x2F;div[1]&#x2F;div[2]&#x2F;h2&#x2F;span&#x2F;text()&quot;)[0]))</span><br><span class=\"line\">if info_num &gt; 3000:</span><br><span class=\"line\">    page_num &#x3D; 100</span><br><span class=\"line\">else:</span><br><span class=\"line\">    page_num &#x3D; math.ceil(info_num&#x2F;30)</span><br><span class=\"line\"></span><br><span class=\"line\">for num in range(page_num):</span><br><span class=\"line\">    url1 &#x3D; url+&quot;pg&quot;+str(num+1)</span><br><span class=\"line\">    req1 &#x3D; requests.get(url1, headers&#x3D;headers)</span><br><span class=\"line\">\tsoup1 &#x3D; BeautifulSoup(req1.text, &quot;lxml&quot;)</span><br><span class=\"line\">    for house in soup1.xpath(&quot;&#x2F;html&#x2F;body&#x2F;div[4]&#x2F;div[1]&#x2F;ul&#x2F;li&quot;):</span><br><span class=\"line\">\t\tinfo &#x3D; house.xpath(&quot;div[1]&#x2F;div[3]&#x2F;div&#x2F;text()&quot;)[0].split(&quot;|&quot;)</span><br><span class=\"line\">\t\tif info[-1].strip()[-2:]&#x3D;&#x3D;&quot; 别墅 &quot; or len(info)&lt;6:</span><br><span class=\"line\">            continue</span><br><span class=\"line\">        try:</span><br><span class=\"line\">            Roomnum &#x3D; info[0].strip()[0]</span><br><span class=\"line\">            Hall &#x3D; info[0].strip()[-2]</span><br><span class=\"line\">            Acreage &#x3D; info[1].strip()</span><br><span class=\"line\">\t\t\tRenovation &#x3D; info[3].strip()</span><br><span class=\"line\">\t\t\tPrice &#x3D; house.xpath(&quot;div[1]&#x2F;div[6]&#x2F;div[2]&#x2F;span&#x2F;text()&quot;)[0][2:]</span><br><span class=\"line\">            Height &#x3D; info[4].strip()[:3]</span><br><span class=\"line\">        except:</span><br><span class=\"line\">            pass</span><br><span class=\"line\"></span><br><span class=\"line\">t2 &#x3D; time.time() # 结束时间</span><br><span class=\"line\">print(&#39; 一般方法，总共耗时：%s&#39; % (t2 - t1))</span><br></pre></td></tr></table></figure><p># 并发（使用 concurrent.futures 模块以及 requests+BeautifulSoup）</p><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">import requests</span><br><span class=\"line\">from bs4 import BeautifulSoup</span><br><span class=\"line\">import time</span><br><span class=\"line\">from concurrent.futures import ThreadPoolExecutor, wait, ALL_COMPLETED</span><br><span class=\"line\">import math</span><br><span class=\"line\"></span><br><span class=\"line\"># 开始时间</span><br><span class=\"line\">t1 &#x3D; time.time()</span><br><span class=\"line\"></span><br><span class=\"line\">url &#x3D; &quot;https:&#x2F;&#x2F;cd.lianjia.com&#x2F;ershoufang&#x2F;&quot;</span><br><span class=\"line\"># 请求头部</span><br><span class=\"line\">headers &#x3D; &#123;&#39;User-Agent&#39;: &#39;Mozilla&#x2F;5.0 (Windows NT 10.0; WOW64) AppleWebKit&#x2F;537.36 (KHTML, like Gecko) Chrome&#x2F;67.0.3396.87 Safari&#x2F;537.36&#39;&#125;</span><br><span class=\"line\"># 发送 HTTP 请求</span><br><span class=\"line\">req &#x3D; requests.get(url, headers&#x3D;headers)</span><br><span class=\"line\"># 解析网页</span><br><span class=\"line\">soup &#x3D; BeautifulSoup(req.text, &quot;lxml&quot;)</span><br><span class=\"line\"># 找到爬取页数</span><br><span class=\"line\">info_num &#x3D; int(soup.xpath(&quot;&#x2F;html&#x2F;body&#x2F;div[4]&#x2F;div[1]&#x2F;div[2]&#x2F;h2&#x2F;span&#x2F;text()&quot;)[0]))</span><br><span class=\"line\">if info_num &gt; 3000:</span><br><span class=\"line\">    page_num &#x3D; 100</span><br><span class=\"line\">else:</span><br><span class=\"line\">    page_num &#x3D; math.ceil(info_num&#x2F;30)</span><br><span class=\"line\"></span><br><span class=\"line\">urls &#x3D; []</span><br><span class=\"line\"># 获取网址</span><br><span class=\"line\">for url1 in page_num:</span><br><span class=\"line\">    urls.append(&#39;https:&#x2F;&#x2F;cd.lianjia.com&#x2F;ershoufang&#x2F;&#39;+&#39;pg&#39;+url1)</span><br><span class=\"line\"></span><br><span class=\"line\"># 获取每个网页信息</span><br><span class=\"line\">def parser(url):</span><br><span class=\"line\">    req1 &#x3D; requests.get(url)</span><br><span class=\"line\">    # 利用 BeautifulSoup 将获取到的文本解析成 HTML</span><br><span class=\"line\">    soup1 &#x3D; BeautifulSoup(req.text, &quot;lxml&quot;)</span><br><span class=\"line\">    # 获取指定信息</span><br><span class=\"line\">\tfor house in soup1.xpath(&quot;&#x2F;html&#x2F;body&#x2F;div[4]&#x2F;div[1]&#x2F;ul&#x2F;li&quot;):</span><br><span class=\"line\">\t\tinfo &#x3D; house.xpath(&quot;div[1]&#x2F;div[3]&#x2F;div&#x2F;text()&quot;)[0].split(&quot;|&quot;)</span><br><span class=\"line\">\t\tif info[-1].strip()[-2:]&#x3D;&#x3D;&quot; 别墅 &quot; or len(info)&lt;6:</span><br><span class=\"line\">            continue</span><br><span class=\"line\">        try:</span><br><span class=\"line\">            Roomnum &#x3D; info[0].strip()[0]</span><br><span class=\"line\">            Hall &#x3D; info[0].strip()[-2]</span><br><span class=\"line\">            Acreage &#x3D; info[1].strip()</span><br><span class=\"line\">\t\t\tRenovation &#x3D; info[3].strip()</span><br><span class=\"line\">\t\t\tPrice &#x3D; house.xpath(&quot;div[1]&#x2F;div[6]&#x2F;div[2]&#x2F;span&#x2F;text()&quot;)[0][2:]</span><br><span class=\"line\">            Height &#x3D; info[4].strip()[:3]</span><br><span class=\"line\">        except:</span><br><span class=\"line\">            pass</span><br><span class=\"line\">    </span><br><span class=\"line\"></span><br><span class=\"line\"># 利用并发加速爬取</span><br><span class=\"line\">executor &#x3D; ThreadPoolExecutor(max_workers&#x3D;20)</span><br><span class=\"line\"># submit() 的参数： 第一个为函数， 之后为该函数的传入参数，允许有多个 </span><br><span class=\"line\">future_tasks &#x3D; [executor.submit(parser, url) for url in urls]</span><br><span class=\"line\"># 等待所有的线程完成，才进入后续的执行</span><br><span class=\"line\">wait(future_tasks, return_when&#x3D;ALL_COMPLETED)</span><br><span class=\"line\"></span><br><span class=\"line\">t2 &#x3D; time.time() # 结束时间</span><br><span class=\"line\">print(&#39; 并发方法，总共耗时：%s&#39; % (t2 - t1))</span><br></pre></td></tr></table></figure><p># 异步（使用 aiohttp+asyncio+requests+BeautifulSoup）</p><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">import requests</span><br><span class=\"line\">from bs4 import BeautifulSoup</span><br><span class=\"line\">import time</span><br><span class=\"line\">import aiohttp</span><br><span class=\"line\">import asyncio</span><br><span class=\"line\">import math</span><br><span class=\"line\"></span><br><span class=\"line\"># 开始时间</span><br><span class=\"line\">t1 &#x3D; time.time()</span><br><span class=\"line\"></span><br><span class=\"line\">url &#x3D; &quot;https:&#x2F;&#x2F;cd.lianjia.com&#x2F;ershoufang&#x2F;&quot;</span><br><span class=\"line\"># 请求头部</span><br><span class=\"line\">headers &#x3D; &#123;&#39;User-Agent&#39;: &#39;Mozilla&#x2F;5.0 (Windows NT 10.0; WOW64) AppleWebKit&#x2F;537.36 (KHTML, like Gecko) Chrome&#x2F;67.0.3396.87 Safari&#x2F;537.36&#39;&#125;</span><br><span class=\"line\"># 发送 HTTP 请求</span><br><span class=\"line\">req &#x3D; requests.get(url, headers&#x3D;headers)</span><br><span class=\"line\"># 解析网页</span><br><span class=\"line\">soup &#x3D; BeautifulSoup(req.text, &quot;lxml&quot;)</span><br><span class=\"line\"># 爬取页数</span><br><span class=\"line\">info_num &#x3D; int(soup.xpath(&quot;&#x2F;html&#x2F;body&#x2F;div[4]&#x2F;div[1]&#x2F;div[2]&#x2F;h2&#x2F;span&#x2F;text()&quot;)[0]))</span><br><span class=\"line\">if info_num &gt; 3000:</span><br><span class=\"line\">    page_num &#x3D; 100</span><br><span class=\"line\">else:</span><br><span class=\"line\">    page_num &#x3D; math.ceil(info_num&#x2F;30)</span><br><span class=\"line\"></span><br><span class=\"line\">urls &#x3D; []</span><br><span class=\"line\"># 获取网址</span><br><span class=\"line\">for human in page_name:</span><br><span class=\"line\">    urls.append(&#39;https:&#x2F;&#x2F;cd.lianjia.com&#x2F;ershoufang&#x2F;&#39;+&#39;pg&#39;+human)</span><br><span class=\"line\"></span><br><span class=\"line\"># 处理网页，获取信息</span><br><span class=\"line\">async def download(url):</span><br><span class=\"line\">    async with aiohttp.ClientSession() as session:</span><br><span class=\"line\">        try:</span><br><span class=\"line\">\t\t\tasync with session.get(url) as response:</span><br><span class=\"line\">\t\t\t\treturn await response.text()</span><br><span class=\"line\">            # 利用 BeautifulSoup 将获取到的文本解析成 HTML</span><br><span class=\"line\">\t\t\tsoup1 &#x3D; BeautifulSoup(response.text(), &quot;lxml&quot;)</span><br><span class=\"line\">\t\t\t# 获取 name 和 description</span><br><span class=\"line\">\t\t\tfor house in soup1.xpath(&quot;&#x2F;html&#x2F;body&#x2F;div[4]&#x2F;div[1]&#x2F;ul&#x2F;li&quot;):</span><br><span class=\"line\">\t\t\t\tinfo &#x3D; house.xpath(&quot;div[1]&#x2F;div[3]&#x2F;div&#x2F;text()&quot;)[0].split(&quot;|&quot;)</span><br><span class=\"line\">\t\t\t\tif info[-1].strip()[-2:]&#x3D;&#x3D;&quot; 别墅 &quot; or len(info)&lt;6:</span><br><span class=\"line\">\t\t\t\t\tcontinue</span><br><span class=\"line\">\t\t\t\tRoomnum &#x3D; info[0].strip()[0]</span><br><span class=\"line\">\t\t\t\tHall &#x3D; info[0].strip()[-2]</span><br><span class=\"line\">\t\t\t\tAcreage &#x3D; info[1].strip()</span><br><span class=\"line\">\t\t\t\tRenovation &#x3D; info[3].strip()</span><br><span class=\"line\">\t\t\t\tPrice &#x3D; house.xpath(&quot;div[1]&#x2F;div[6]&#x2F;div[2]&#x2F;span&#x2F;text()&quot;)[0][2:]</span><br><span class=\"line\">\t\t\t\tHeight &#x3D; info[4].strip()[:3]</span><br><span class=\"line\">\t\texcept Exception as err:</span><br><span class=\"line\">            print(err)</span><br><span class=\"line\"></span><br><span class=\"line\"># 利用 asyncio 模块进行异步 IO 处理</span><br><span class=\"line\">loop &#x3D; asyncio.get_event_loop()</span><br><span class=\"line\">tasks &#x3D; [asyncio.ensure_future(download(url)) for url in urls]</span><br><span class=\"line\">tasks &#x3D; asyncio.gather(*tasks)</span><br><span class=\"line\">loop.run_until_complete(tasks)</span><br><span class=\"line\"></span><br><span class=\"line\">t2 &#x3D; time.time() # 结束时间</span><br><span class=\"line\">print(&#39; 使用异步，总共耗时：%s&#39; % (t2 - t1))</span><br></pre></td></tr></table></figure><p># 使用框架 Scrapy<br><em><strong> 框架教程较多，可自行百度</strong></em><br><strong>Scrapy 来制作爬虫的优势在于它是一个成熟的爬虫框架，支持异步，并发，容错性较好，但如果需要频繁地修改中间件，则还是自己写个爬虫比较好，而且它在速度上没有超过我们自己写的异步爬虫，能自动导出 CSV 文件这个功能，总体来说比较方便。</strong></p>","url":"/posts/4/","min2read":7,"word4post":"1.5k","prev_post":{"title":"python 数据清洗","url":"/posts/5/"},"next_post":{"title":"爬虫被识别处理方法","url":"/posts/3/"},"toc":"<ol class=\"toc\"><li class=\"toc-item toc-level-1\"><a class=\"toc-link\" data-id=\"\" href = \"#\"><span class=\"toc-number\">1.</span> <span class=\"toc-text\"> 同步、并发、异步、框架概念区别 </span></a></li><li class=\"toc-item toc-level-1\"><a class=\"toc-link\" data-id=\"\" href = \"#\"><span class=\"toc-number\">2.</span> <span class=\"toc-text\"> 一般方法（同步、requests+beautifulsoup）</span></a></li></ol>","categories":[{"name":"python","path":"api/categories/python.json","url":"/categories/python/"}],"tags":[{"name":"爬虫","path":"api/tags/爬虫.json","url":"/tags/爬虫/"}]}